----------------------------------2
----------------------------------3
----------------------------------4
----------------------------------5
----------------------------------6
----------------------------------sent
env.action_space is [MultiDiscrete2, Discrete(5), Discrete(5), Discrete(5), Discrete(5), Discrete(5)] 
env.observation_space is [Box(34,), Box(34,), Box(34,), Box(34,), Box(28,), Box(28,)] 
obs_shape_n is [(34,), (34,), (34,), (34,), (28,), (28,)] 
Using good policy maddpg and adv policy maddpg
[Discrete(34), Discrete(34), Discrete(34), Discrete(34), Discrete(28), Discrete(28)]
Using noise policy maddpg
There is 6 adversaries
Starting iterations...
steps: 24975, episodes: 1000, mean episode reward: -26.506034461454846, agent episode reward: [1.170736150935406, 0.9115823201997731, 1.1061642127044318, 1.093620414749991, -22.49593845399377, -8.292199106050672], time: 289.182
steps: 49975, episodes: 2000, mean episode reward: -39.71820473945795, agent episode reward: [1.703336825372862, 1.6126173474606544, 2.3474650331364773, 1.6787283683424117, -29.417954195582084, -17.64239811818828], time: 361.094
steps: 74975, episodes: 3000, mean episode reward: 1.4230002156119295, agent episode reward: [2.7533376426237663, 1.8109305200040169, 2.368470628334294, 2.267471923179302, -5.443773800706219, -2.333436697823231], time: 415.804
steps: 99975, episodes: 4000, mean episode reward: -0.34090311312955407, agent episode reward: [2.9674249987031316, 2.337652124256622, 3.0470485602917323, 2.7054972264774015, -9.004244309355071, -2.39428171350337], time: 378.982
steps: 124975, episodes: 5000, mean episode reward: 2.668222239221617, agent episode reward: [3.6476315973915954, 3.5581449287937152, 4.168520464579376, 3.6560116481243323, -8.589631897881294, -3.7724545017861084], time: 375.55
steps: 149975, episodes: 6000, mean episode reward: 7.5875369877874705, agent episode reward: [4.306598872776195, 4.4837962136933, 4.821327290822355, 4.255570001283335, -6.569038644845505, -3.7107167459422072], time: 367.406
steps: 174975, episodes: 7000, mean episode reward: 11.007827336811955, agent episode reward: [4.971418683528933, 5.280390164902341, 5.393516133222478, 5.169621972396574, -5.604245323865756, -4.202874293372612], time: 403.685
steps: 199975, episodes: 8000, mean episode reward: 12.497077854462695, agent episode reward: [5.983556756050875, 5.974730197038607, 6.183835309388671, 6.066102853563941, -6.8213056058491635, -4.889841655730239], time: 396.76
steps: 224975, episodes: 9000, mean episode reward: 11.362307500371069, agent episode reward: [5.863629748742246, 5.630150260397604, 5.806496543565581, 5.923126716627628, -7.151165105216061, -4.709930663745928], time: 370.301
steps: 249975, episodes: 10000, mean episode reward: 12.812518541474418, agent episode reward: [5.953247168474218, 5.649540356851657, 5.665078579134777, 5.98940620735216, -5.904263622638884, -4.54049014769951], time: 394.194
steps: 274975, episodes: 11000, mean episode reward: 10.283627661080077, agent episode reward: [5.0320589319635785, 4.621699708984277, 4.740208363786204, 5.035097034862035, -5.417361115698693, -3.728075262817324], time: 440.214
steps: 299975, episodes: 12000, mean episode reward: 14.776138523913335, agent episode reward: [6.676895879385064, 6.3577087171963065, 6.507879980032245, 6.649255413115944, -5.867624152044893, -5.54797731377133], time: 404.955
steps: 324975, episodes: 13000, mean episode reward: 11.322325424090513, agent episode reward: [6.055334983152636, 5.861330606580759, 6.013774802036476, 6.0875367674025505, -6.245130915060542, -6.4505208200213655], time: 389.189
steps: 349975, episodes: 14000, mean episode reward: 10.941677737851936, agent episode reward: [6.6458111505797985, 6.506958233063629, 6.6861033401911625, 6.643353992544925, -6.9849993185234505, -8.555549660004129], time: 407.881
steps: 374975, episodes: 15000, mean episode reward: 7.127522331042823, agent episode reward: [6.898780242516844, 6.881149218694467, 6.943282491007168, 6.8421906608849685, -7.712245833472061, -12.725634448588565], time: 393.858
steps: 399975, episodes: 16000, mean episode reward: 8.168004649564649, agent episode reward: [6.8129266371385375, 6.798682533730185, 6.857023321979093, 6.823648214709352, -8.529627932827312, -10.594648125165207], time: 411.312
steps: 424975, episodes: 17000, mean episode reward: 15.335517142748792, agent episode reward: [7.7888770857663046, 7.792805333801675, 7.8546996834988185, 7.79852514730787, -8.845779705997673, -7.0536104016282035], time: 371.342
steps: 449975, episodes: 18000, mean episode reward: 15.710937177385057, agent episode reward: [7.699561169742663, 7.725236870407447, 7.823592048179961, 7.710443156769992, -7.9294967016472375, -7.3183993660677675], time: 336.522
steps: 474975, episodes: 19000, mean episode reward: 10.430781312700212, agent episode reward: [7.384043519229392, 7.46955879958177, 7.521428927912962, 7.444653073746966, -7.898514105807007, -11.490388901963868], time: 314.094
steps: 499975, episodes: 20000, mean episode reward: 9.197177625781855, agent episode reward: [6.744406636765822, 6.856402039730178, 7.0004170560964125, 6.858641643350929, -9.361326202895691, -8.901363547265795], time: 357.805
steps: 524975, episodes: 21000, mean episode reward: 5.724128982305999, agent episode reward: [5.998739481798568, 6.072830379806594, 6.2427355468921455, 6.101986868665352, -9.653884003400048, -9.038279291456613], time: 351.131
steps: 549975, episodes: 22000, mean episode reward: 10.261086555449268, agent episode reward: [6.970197932659963, 7.116337646497455, 7.222584535305184, 7.121273773234859, -9.730878807441302, -8.438428524806891], time: 369.94
steps: 574975, episodes: 23000, mean episode reward: 4.2919445986718205, agent episode reward: [6.032512310195065, 6.024578415651809, 6.2269748001047684, 6.118294388581956, -11.393996915442793, -8.716418400418984], time: 352.91
steps: 599975, episodes: 24000, mean episode reward: 6.3517046716658365, agent episode reward: [6.233763362103479, 6.263161064773675, 6.534614492594979, 6.347875860414865, -11.3404901761136, -7.687219932107562], time: 331.937
steps: 624975, episodes: 25000, mean episode reward: 2.623589934957981, agent episode reward: [6.13179983451748, 6.095253924664947, 6.210161308774461, 6.1079125607584706, -10.736068003273093, -11.185469690484286], time: 333.082
steps: 649975, episodes: 26000, mean episode reward: 1.3701745670849932, agent episode reward: [5.978096304003603, 5.9371739424337715, 6.139704548927361, 5.9599781666348175, -10.67722606612257, -11.967552328791989], time: 342.255
steps: 674975, episodes: 27000, mean episode reward: 0.9331009237748099, agent episode reward: [6.633035521321666, 6.540672275871769, 6.770205892061747, 6.60785001676878, -12.38802810182494, -13.23063468042421], time: 335.678
steps: 699975, episodes: 28000, mean episode reward: -1.4354185897885172, agent episode reward: [6.194185434235212, 6.064792890895729, 6.3592066503222595, 6.152902508282138, -10.531678003309958, -15.674828070213898], time: 280.117
steps: 724975, episodes: 29000, mean episode reward: 0.6493781888243336, agent episode reward: [6.282587757363666, 6.238496457457182, 6.445265576590817, 6.244826338086933, -10.794410309104792, -13.767387631569472], time: 259.81
steps: 749975, episodes: 30000, mean episode reward: -3.133209843754091, agent episode reward: [6.225611156031551, 6.189600388223402, 6.332191115981707, 6.174944472449796, -11.995148061867502, -16.060408914573046], time: 249.186
steps: 774975, episodes: 31000, mean episode reward: -1.0952442286109543, agent episode reward: [6.1818063968721795, 6.127427856815592, 6.289324654403749, 6.129408301432659, -12.8636400124727, -12.95957142566243], time: 243.424
steps: 799975, episodes: 32000, mean episode reward: -0.8603849407448517, agent episode reward: [6.055448030828103, 6.0082810585139725, 6.121113121172507, 5.9417592638441565, -10.975183718154572, -14.011802696949017], time: 239.774
steps: 824975, episodes: 33000, mean episode reward: 1.5320255676132861, agent episode reward: [6.344387354440087, 6.315028614070761, 6.409614004013525, 6.292244088149061, -10.5467785041354, -13.282469988924749], time: 266.209
steps: 849975, episodes: 34000, mean episode reward: 0.5287613987608343, agent episode reward: [6.250709683674442, 6.264555235221278, 6.403940084541818, 6.288952930633581, -12.172032162266081, -12.507364373044206], time: 262.254
steps: 874975, episodes: 35000, mean episode reward: -2.23311833574609, agent episode reward: [5.9775898250065955, 5.991139805573294, 6.128003149215086, 6.0008181226401955, -11.693094554410429, -14.637574683770833], time: 238.185
steps: 899975, episodes: 36000, mean episode reward: -0.9915636347695094, agent episode reward: [5.841535201122506, 5.896717447482952, 5.998005903321282, 5.877405752547209, -11.371353026537843, -13.233874912705613], time: 283.472
steps: 924975, episodes: 37000, mean episode reward: -3.4359060189108384, agent episode reward: [6.064964537601405, 6.024073306951194, 6.20127604767427, 6.045390987289275, -10.983239324609206, -16.788371573817777], time: 326.572
steps: 949975, episodes: 38000, mean episode reward: -7.210184507627457, agent episode reward: [5.73686671716666, 5.768931361440298, 5.844953402856816, 5.7657722135722524, -12.819423354684686, -17.507284847978802], time: 317.941
steps: 974975, episodes: 39000, mean episode reward: -4.808271610144861, agent episode reward: [5.864840915941378, 5.894064286246248, 5.971349978914108, 5.845805936354048, -10.966151462051227, -17.418181265549414], time: 312.537
steps: 999975, episodes: 40000, mean episode reward: -6.467940716109648, agent episode reward: [5.945035004414382, 5.997535058726705, 6.126500110358796, 5.955269124810686, -12.3160325086692, -18.176247505751018], time: 307.496
steps: 1024975, episodes: 41000, mean episode reward: -4.394565262478485, agent episode reward: [5.887074713323313, 5.921584341299707, 6.016211820362538, 5.807058343688044, -12.480357414087212, -15.546137067064876], time: 294.034
steps: 1049975, episodes: 42000, mean episode reward: -4.661541745411288, agent episode reward: [5.5144677303842675, 5.624929485323974, 5.6927570788621225, 5.527347116108445, -10.950622629205286, -16.07042052688481], time: 315.897
steps: 1074975, episodes: 43000, mean episode reward: -8.985974272423675, agent episode reward: [5.4716136334944485, 5.542562602987604, 5.640299680977283, 5.507217609663188, -13.870599624937396, -17.277068174608804], time: 268.006
steps: 1099975, episodes: 44000, mean episode reward: -5.315437747793204, agent episode reward: [5.771032763161275, 5.799570830906036, 5.878563108574562, 5.769575401990718, -10.598585224335677, -17.93559462809012], time: 340.432
steps: 1124975, episodes: 45000, mean episode reward: -4.733018901853633, agent episode reward: [5.361066711797344, 5.404157739220175, 5.495705693161022, 5.369414902407496, -9.579297076635637, -16.784066871804033], time: 315.569
steps: 1149975, episodes: 46000, mean episode reward: -5.241433025943637, agent episode reward: [5.795633551692946, 5.790512327546318, 5.978963155006189, 5.854624798798205, -10.469682245930503, -18.19148461305679], time: 289.835
steps: 1174975, episodes: 47000, mean episode reward: 0.8041539637475591, agent episode reward: [6.494478680541626, 6.526699251695774, 6.60084823830926, 6.465245399833072, -10.443905631394239, -14.839211975237934], time: 304.073
steps: 1199975, episodes: 48000, mean episode reward: -0.5171755094981964, agent episode reward: [5.74568609976563, 5.6943505093036775, 5.886543291309767, 5.77808743211182, -10.809853672833327, -12.811989169155764], time: 331.959
steps: 1224975, episodes: 49000, mean episode reward: -4.884656328136072, agent episode reward: [5.2245305481540525, 5.173263987229297, 5.318676795871373, 5.251696113490283, -11.920862921223813, -13.931960851657262], time: 305.865
steps: 1249975, episodes: 50000, mean episode reward: -1.1898304842185412, agent episode reward: [5.571497591839494, 5.573876755843113, 5.67350065607136, 5.62458467765056, -10.67639962492214, -12.956890540700929], time: 282.563
steps: 1274975, episodes: 51000, mean episode reward: -4.367226745061658, agent episode reward: [5.148653749849851, 5.107574320911162, 5.232318654196963, 5.1665052209819695, -11.321914371328592, -13.700364319673014], time: 318.297
steps: 1299975, episodes: 52000, mean episode reward: 0.39230575704277876, agent episode reward: [5.948487070576571, 5.95514270342529, 5.925755617988032, 5.903439083009987, -12.249423374929465, -11.09109534302764], time: 308.853
steps: 1324975, episodes: 53000, mean episode reward: 3.8903281113158035, agent episode reward: [5.919725075686626, 5.969161069414666, 5.987101833807228, 5.9272100932509915, -10.576096742107588, -9.336773218736122], time: 308.343
steps: 1349975, episodes: 54000, mean episode reward: 4.603356443229919, agent episode reward: [5.999136256404366, 5.979333960172567, 6.041441562881826, 5.929075220297214, -10.914038763838459, -8.431591792687595], time: 294.46
steps: 1374975, episodes: 55000, mean episode reward: 3.6316557730672083, agent episode reward: [5.734592292687248, 5.742284400755052, 5.7866969274802065, 5.638126469454248, -11.485878345777898, -7.784165971531648], time: 290.457
steps: 1399975, episodes: 56000, mean episode reward: 4.767825711497162, agent episode reward: [5.695607658081992, 5.649742837402849, 5.716499584615434, 5.551677916698134, -11.03808145354527, -6.807620831755978], time: 295.203
steps: 1424975, episodes: 57000, mean episode reward: -0.9368623478931306, agent episode reward: [5.6917474554645215, 5.612055009197238, 5.693036568419482, 5.575981822565566, -12.742396853849012, -10.767286349690927], time: 304.785
steps: 1449975, episodes: 58000, mean episode reward: -1.9346580348603644, agent episode reward: [4.9138992414576625, 4.842648128778379, 4.891461974363632, 4.80348309010527, -13.151867399340482, -8.234283070224826], time: 299.918
steps: 1474975, episodes: 59000, mean episode reward: -5.337285405060382, agent episode reward: [5.458507315498089, 5.387805062998765, 5.376347914062238, 5.321001204313547, -15.772800391119686, -11.108146510813336], time: 291.658
steps: 1499975, episodes: 60000, mean episode reward: 1.7871634458467265, agent episode reward: [5.67244059151, 5.734941325258959, 5.629520994604982, 5.558798221287619, -13.760914354871133, -7.0476233319437], time: 290.956
...Finished total of 60001 episodes.
----------------------------------2
----------------------------------3
----------------------------------4
----------------------------------5
----------------------------------6
----------------------------------end
