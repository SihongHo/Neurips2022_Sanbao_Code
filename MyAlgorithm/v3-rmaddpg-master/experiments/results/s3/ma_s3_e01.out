env.action_space is [Discrete(5), Discrete(5), Discrete(5)] 
env.observation_space is [Box(18,), Box(18,), Box(18,)] 
obs_shape_n is [(18,), (18,), (18,)] 
Using good policy maddpg and adv policy maddpg
[Discrete(18), Discrete(18), Discrete(18)]
Using noise policy maddpg
There is 3 adversaries
Starting iterations...
steps: 24975, episodes: 1000, mean episode reward: -674.0173246566766, time: 89.715
steps: 49975, episodes: 2000, mean episode reward: -751.4345198589886, time: 117.144
steps: 74975, episodes: 3000, mean episode reward: -617.8061074541702, time: 114.371
steps: 99975, episodes: 4000, mean episode reward: -597.9792486442996, time: 114.231
steps: 124975, episodes: 5000, mean episode reward: -599.2202714962358, time: 113.616
steps: 149975, episodes: 6000, mean episode reward: -602.6097026489675, time: 115.607
steps: 174975, episodes: 7000, mean episode reward: -603.4873201461545, time: 115.251
steps: 199975, episodes: 8000, mean episode reward: -608.0333823291049, time: 114.111
steps: 224975, episodes: 9000, mean episode reward: -610.5027778419403, time: 116.128
steps: 249975, episodes: 10000, mean episode reward: -607.9306091739712, time: 115.968
steps: 274975, episodes: 11000, mean episode reward: -612.4899473474005, time: 117.417
steps: 299975, episodes: 12000, mean episode reward: -616.9423885600322, time: 118.362
steps: 324975, episodes: 13000, mean episode reward: -618.3919002997882, time: 117.077
steps: 349975, episodes: 14000, mean episode reward: -619.4116801409305, time: 115.496
steps: 374975, episodes: 15000, mean episode reward: -609.4762177034473, time: 119.949
steps: 399975, episodes: 16000, mean episode reward: -616.9394953268043, time: 117.126
steps: 424975, episodes: 17000, mean episode reward: -618.683951080153, time: 119.137
steps: 449975, episodes: 18000, mean episode reward: -620.7456007669775, time: 117.229
steps: 474975, episodes: 19000, mean episode reward: -618.1044484707616, time: 119.129
steps: 499975, episodes: 20000, mean episode reward: -619.9485260869963, time: 118.825
steps: 524975, episodes: 21000, mean episode reward: -616.190699847952, time: 117.255
steps: 549975, episodes: 22000, mean episode reward: -625.3619224699347, time: 131.804
steps: 574975, episodes: 23000, mean episode reward: -622.9637545321095, time: 131.955
steps: 599975, episodes: 24000, mean episode reward: -623.5562086515125, time: 131.204
steps: 624975, episodes: 25000, mean episode reward: -623.2574501498658, time: 130.661
steps: 649975, episodes: 26000, mean episode reward: -625.1534137273806, time: 130.998
steps: 674975, episodes: 27000, mean episode reward: -621.5728444958334, time: 130.774
steps: 699975, episodes: 28000, mean episode reward: -618.5806257305842, time: 132.079
steps: 724975, episodes: 29000, mean episode reward: -623.2994465406273, time: 131.825
steps: 749975, episodes: 30000, mean episode reward: -618.9632699475014, time: 130.7
steps: 774975, episodes: 31000, mean episode reward: -620.6667896976555, time: 130.819
steps: 799975, episodes: 32000, mean episode reward: -619.07507948024, time: 131.441
steps: 824975, episodes: 33000, mean episode reward: -619.8333325389875, time: 130.729
steps: 849975, episodes: 34000, mean episode reward: -625.2715018310938, time: 130.97
steps: 874975, episodes: 35000, mean episode reward: -622.8909679419885, time: 131.292
steps: 899975, episodes: 36000, mean episode reward: -625.197230902263, time: 130.998
steps: 924975, episodes: 37000, mean episode reward: -624.7768996784808, time: 130.346
steps: 949975, episodes: 38000, mean episode reward: -614.8915050198723, time: 131.897
steps: 974975, episodes: 39000, mean episode reward: -618.4741894117851, time: 131.766
steps: 999975, episodes: 40000, mean episode reward: -619.2086562278744, time: 130.65
steps: 1024975, episodes: 41000, mean episode reward: -621.3250195127623, time: 131.017
steps: 1049975, episodes: 42000, mean episode reward: -617.0848175724286, time: 131.418
steps: 1074975, episodes: 43000, mean episode reward: -616.9509804088043, time: 131.548
steps: 1099975, episodes: 44000, mean episode reward: -618.6631188072449, time: 132.008
steps: 1124975, episodes: 45000, mean episode reward: -624.9976515007786, time: 131.8
steps: 1149975, episodes: 46000, mean episode reward: -623.6942878135417, time: 130.898
steps: 1174975, episodes: 47000, mean episode reward: -622.0082528256767, time: 131.223
steps: 1199975, episodes: 48000, mean episode reward: -622.76830276355, time: 130.886
steps: 1224975, episodes: 49000, mean episode reward: -623.948000303911, time: 131.134
steps: 1249975, episodes: 50000, mean episode reward: -613.3789905462927, time: 130.743
steps: 1274975, episodes: 51000, mean episode reward: -616.422188496724, time: 117.658
steps: 1299975, episodes: 52000, mean episode reward: -612.6049970701265, time: 116.104
steps: 1324975, episodes: 53000, mean episode reward: -616.9908916270887, time: 116.088
steps: 1349975, episodes: 54000, mean episode reward: -613.9167948559812, time: 115.456
steps: 1374975, episodes: 55000, mean episode reward: -612.6152130284476, time: 116.147
steps: 1399975, episodes: 56000, mean episode reward: -620.7676876545409, time: 115.955
steps: 1424975, episodes: 57000, mean episode reward: -616.1010855512131, time: 116.284
steps: 1449975, episodes: 58000, mean episode reward: -617.1485026908213, time: 116.208
steps: 1474975, episodes: 59000, mean episode reward: -609.1912910913254, time: 128.309
steps: 1499975, episodes: 60000, mean episode reward: -609.1600167871804, time: 132.511
...Finished total of 60001 episodes.
