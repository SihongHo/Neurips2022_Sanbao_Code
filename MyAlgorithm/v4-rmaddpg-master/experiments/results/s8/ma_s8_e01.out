----------------------------------2
----------------------------------3
----------------------------------4
----------------------------------5
----------------------------------6
----------------------------------sent
env.action_space is [MultiDiscrete2, Discrete(5), Discrete(5), Discrete(5), Discrete(5), Discrete(5)] 
env.observation_space is [Box(34,), Box(34,), Box(34,), Box(34,), Box(28,), Box(28,)] 
obs_shape_n is [(34,), (34,), (34,), (34,), (28,), (28,)] 
Using good policy maddpg and adv policy maddpg
[Discrete(34), Discrete(34), Discrete(34), Discrete(34), Discrete(28), Discrete(28)]
Using noise policy maddpg
There is 6 adversaries
Starting iterations...
steps: 24975, episodes: 1000, mean episode reward: -53.45341938292791, agent episode reward: [0.7624289084237188, 0.9335047346056005, 0.8402442077139518, 0.7462945431696107, -28.916935141428386, -27.818956635412402], time: 259.097
steps: 49975, episodes: 2000, mean episode reward: -74.05247146545243, agent episode reward: [2.443411658868013, 2.5970216014006433, 1.5879095118400754, 2.1471705203283578, -25.735915625471094, -57.092069132418416], time: 383.345
steps: 74975, episodes: 3000, mean episode reward: 7.45103770018038, agent episode reward: [3.611627210751266, 4.063352973499141, 4.13245794500938, 4.013935380131813, -3.9047398607505017, -4.465595948460718], time: 326.004
steps: 99975, episodes: 4000, mean episode reward: 7.497486037551762, agent episode reward: [4.459491356459959, 4.663260595231737, 4.652451685705271, 4.700644986862247, -5.216587626401368, -5.761774960306083], time: 320.218
steps: 124975, episodes: 5000, mean episode reward: 6.416549754495789, agent episode reward: [4.0788423046581945, 3.9778432619273842, 4.100208641238141, 4.005382510918235, -4.852164545310313, -4.893562418935852], time: 324.466
steps: 149975, episodes: 6000, mean episode reward: 7.8304193752412266, agent episode reward: [4.809674455694702, 4.780644844884523, 4.864395032158003, 4.644324301511233, -5.752010758676091, -5.5166085003311425], time: 373.537
steps: 174975, episodes: 7000, mean episode reward: 9.992392808611104, agent episode reward: [5.605189043186729, 5.63081496377858, 5.6057767522461965, 5.633029345114211, -5.064780527803652, -7.417636767910959], time: 418.986
steps: 199975, episodes: 8000, mean episode reward: 10.752530859638643, agent episode reward: [6.1457482743561425, 6.183301212788266, 6.041635577672238, 6.137072376400465, -6.623370292281101, -7.131856289297367], time: 351.442
steps: 224975, episodes: 9000, mean episode reward: 15.549949276799504, agent episode reward: [7.434651536084828, 7.549920747288943, 7.47119317066532, 7.390858792365051, -6.812047902193264, -7.484627067411376], time: 373.753
steps: 249975, episodes: 10000, mean episode reward: 18.274918207183852, agent episode reward: [8.55849522199706, 8.61076887918446, 8.60788084371647, 8.406094451986162, -8.418772866027584, -7.489548323672716], time: 318.161
steps: 274975, episodes: 11000, mean episode reward: 16.978162691726887, agent episode reward: [7.926071537193609, 7.72423738433747, 7.856943339469006, 7.629476464145498, -7.644203788612219, -6.514362244806472], time: 404.778
steps: 299975, episodes: 12000, mean episode reward: 18.86641595613141, agent episode reward: [8.170826338054532, 8.08663463092035, 8.156597696744381, 7.998631150240053, -7.274364896371683, -6.271908963456227], time: 392.774
steps: 324975, episodes: 13000, mean episode reward: 16.83144205228529, agent episode reward: [8.07984055174506, 7.9731113074824, 7.940119220433649, 7.872275741655755, -7.735117983267789, -7.298786785763786], time: 382.929
steps: 349975, episodes: 14000, mean episode reward: 17.058088734973015, agent episode reward: [8.491890485943536, 8.387100289023234, 8.30705977661989, 8.329707301875656, -8.752674330006995, -7.704994788482311], time: 349.42
steps: 374975, episodes: 15000, mean episode reward: 16.323893128910544, agent episode reward: [8.370798907246375, 8.38152647573711, 8.314101005506474, 8.309729262554542, -8.95103069378559, -8.101231828348366], time: 359.99
steps: 399975, episodes: 16000, mean episode reward: 14.395678038381874, agent episode reward: [8.20827882290783, 8.136000910438163, 8.063587705790745, 8.12210057684201, -10.027818369861695, -8.106471607735182], time: 370.56
steps: 424975, episodes: 17000, mean episode reward: 12.57264879628352, agent episode reward: [7.658463681234546, 7.596180856414651, 7.527945684109108, 7.616308489365855, -9.26424741671993, -8.562002498120707], time: 361.954
steps: 449975, episodes: 18000, mean episode reward: 12.787045930207437, agent episode reward: [7.771568780531614, 7.699067863590607, 7.645899577852324, 7.649069794676088, -9.446463882821169, -8.532096203622027], time: 295.274
steps: 474975, episodes: 19000, mean episode reward: 5.597924830050906, agent episode reward: [7.20064324390092, 7.132707506565778, 7.045835528553658, 7.081313843236535, -12.215098376127846, -10.64747691607814], time: 365.477
steps: 499975, episodes: 20000, mean episode reward: 12.207637554479868, agent episode reward: [7.5513774561508145, 7.4837438178078575, 7.349873552121364, 7.387944159716683, -7.906946152825676, -9.658355278491173], time: 336.991
steps: 524975, episodes: 21000, mean episode reward: 13.831826724730746, agent episode reward: [7.428729056790467, 7.440332650587911, 7.334836971043682, 7.34809022000496, -7.171057700721013, -8.54910447297526], time: 341.93
steps: 549975, episodes: 22000, mean episode reward: 10.450078169468572, agent episode reward: [7.452091646162659, 7.454127785243982, 7.381651596746322, 7.417335373407015, -10.34860440764702, -8.906523824444383], time: 313.097
steps: 574975, episodes: 23000, mean episode reward: 6.151254556099486, agent episode reward: [6.642738949677896, 6.710449903082602, 6.645089742231859, 6.502133975163537, -11.634219465690599, -8.714938548365808], time: 337.215
steps: 599975, episodes: 24000, mean episode reward: 2.433872872853159, agent episode reward: [6.063784605189333, 6.130964613284928, 6.008938136096182, 5.919669205564126, -12.777968005455932, -8.911515681825476], time: 343.425
steps: 624975, episodes: 25000, mean episode reward: 8.241992837009777, agent episode reward: [6.9066303617711, 6.94283919348531, 6.867043884266842, 6.646509910207458, -9.255137535480387, -9.86589297724055], time: 387.689
steps: 649975, episodes: 26000, mean episode reward: 1.7127562612511396, agent episode reward: [6.28008387134007, 6.257473693401774, 6.2389679365425526, 6.025823856501748, -11.31723051605341, -11.772362580481595], time: 336.143
steps: 674975, episodes: 27000, mean episode reward: -4.107683472341645, agent episode reward: [5.538228743452316, 5.5196057432845285, 5.459490666443451, 5.3380290261886785, -13.421566735428515, -12.541470916282105], time: 358.903
steps: 699975, episodes: 28000, mean episode reward: -6.015153924177745, agent episode reward: [5.502449456468966, 5.47521154275352, 5.4429891414959055, 5.438977496911111, -14.801002327843898, -13.073779233963345], time: 349.326
steps: 724975, episodes: 29000, mean episode reward: -2.324233409207332, agent episode reward: [5.807076563091968, 5.780035465207256, 5.80703292926506, 5.698041373112313, -12.307495415712637, -13.10892432417129], time: 328.192
steps: 749975, episodes: 30000, mean episode reward: 1.1357867201756664, agent episode reward: [6.573226083200438, 6.568003083236519, 6.544855886598049, 6.541601372101275, -10.996736732674552, -14.09516297228606], time: 277.991
steps: 774975, episodes: 31000, mean episode reward: 1.1747329382632374, agent episode reward: [5.787794120340104, 5.786559774409165, 5.760310906568873, 5.802387141512576, -9.89367649609714, -12.068642508470342], time: 282.21
steps: 799975, episodes: 32000, mean episode reward: 3.21189334285701, agent episode reward: [6.242795691529229, 6.258624086866057, 6.299672746385696, 6.2992722535497885, -9.180401660660985, -12.70806977481278], time: 279.553
steps: 824975, episodes: 33000, mean episode reward: 0.9742411579453081, agent episode reward: [5.952539778895847, 5.873155577057436, 5.926727647295027, 5.9220982225295025, -9.275675784174027, -13.424604283658475], time: 282.348
steps: 849975, episodes: 34000, mean episode reward: 1.2612623323668852, agent episode reward: [6.118515294060216, 6.005871790744376, 6.004699377712569, 6.088171709721357, -10.695910158295314, -12.260085681576323], time: 276.73
steps: 874975, episodes: 35000, mean episode reward: 2.3369077404430687, agent episode reward: [5.587573746684404, 5.5141293832971945, 5.455368384604188, 5.616268540852987, -9.581834674071903, -10.254597640923803], time: 270.084
steps: 899975, episodes: 36000, mean episode reward: 1.6200671789160128, agent episode reward: [5.141246812280823, 5.116506844566437, 5.072316372488036, 5.179704298398648, -10.307904023246243, -8.581803125571689], time: 270.09
steps: 924975, episodes: 37000, mean episode reward: 3.0143685002770115, agent episode reward: [5.801913021156435, 5.807840982718121, 5.778825557042566, 5.875257971187595, -11.05293979192618, -9.196529239901523], time: 267.502
steps: 949975, episodes: 38000, mean episode reward: 2.7639332292655063, agent episode reward: [5.814963167687903, 5.736690880636577, 5.773239646218374, 5.74591567199797, -10.993443009512019, -9.313433127763302], time: 292.038
steps: 974975, episodes: 39000, mean episode reward: 3.332108239302706, agent episode reward: [5.919460429526079, 5.7800825553060955, 5.782623355917207, 5.883697755091383, -12.051951386264994, -7.981804470273064], time: 359.722
steps: 999975, episodes: 40000, mean episode reward: -0.030675049161725157, agent episode reward: [5.399192008224331, 5.2408266908307946, 5.265304176155861, 5.354201140931108, -12.830933378581841, -8.459265686721977], time: 299.947
steps: 1024975, episodes: 41000, mean episode reward: 1.7621944377725458, agent episode reward: [5.239740448469796, 5.345486271329773, 5.287884747016171, 5.407873993310796, -12.61051892442175, -6.9082720979322385], time: 307.924
steps: 1049975, episodes: 42000, mean episode reward: 5.330349636319633, agent episode reward: [5.971010028217693, 5.991531725977341, 6.092788740915663, 6.064046684379771, -11.72417987434211, -7.064847668828724], time: 300.828
steps: 1074975, episodes: 43000, mean episode reward: 8.76782126253883, agent episode reward: [6.31530109066908, 6.483926006677461, 6.468261892790893, 6.468402387247089, -10.898751652975957, -6.0693184618697344], time: 324.023
steps: 1099975, episodes: 44000, mean episode reward: 6.98139158266909, agent episode reward: [5.57500451617123, 5.785630741052558, 5.833619062067232, 5.7786085021955405, -10.14280136588875, -5.8486698729287205], time: 325.39
steps: 1124975, episodes: 45000, mean episode reward: 6.510761076720488, agent episode reward: [4.904298504425047, 5.194416655808196, 5.170992990105445, 5.112003538372029, -8.374042026668889, -5.49690858532134], time: 282.674
steps: 1149975, episodes: 46000, mean episode reward: 3.786292630371536, agent episode reward: [4.258741082000193, 4.588119015338261, 4.3312348195255455, 4.467015609708214, -8.304848168684401, -5.553969727516276], time: 296.868
steps: 1174975, episodes: 47000, mean episode reward: 10.691484624022218, agent episode reward: [5.864837096140645, 6.1585272080970626, 6.169760938721477, 6.136130151589438, -8.178459331758145, -5.459311438768261], time: 319.412
steps: 1199975, episodes: 48000, mean episode reward: 11.163758747838033, agent episode reward: [5.85150231941763, 6.064050222058959, 6.007729298564611, 6.023198581420812, -7.0777565074580036, -5.704965166165975], time: 317.181
steps: 1224975, episodes: 49000, mean episode reward: 8.548252575132967, agent episode reward: [5.337483377995084, 5.639903575107939, 5.627379371839364, 5.57148640964347, -7.5468728351647805, -6.081127324288108], time: 286.189
steps: 1249975, episodes: 50000, mean episode reward: 10.451710228027503, agent episode reward: [5.778737254323619, 6.045708177936011, 6.0287398477778815, 5.985793502497497, -7.172406422331646, -6.2148621321758615], time: 326.967
steps: 1274975, episodes: 51000, mean episode reward: 13.141839485113406, agent episode reward: [6.43634246524391, 6.61867667530666, 6.683554354009903, 6.5147606407854095, -7.240361639882273, -5.8711330103502], time: 325.771
steps: 1299975, episodes: 52000, mean episode reward: 10.773169573918862, agent episode reward: [6.2328279382466025, 6.337505466411123, 6.316610719800691, 6.2133798927498995, -8.269645895478556, -6.0575085478108965], time: 315.557
steps: 1324975, episodes: 53000, mean episode reward: 10.082680637834521, agent episode reward: [6.314681705776958, 6.401171272431245, 6.378763113729523, 6.309516008435363, -8.977630921605869, -6.343820540932704], time: 318.66
steps: 1349975, episodes: 54000, mean episode reward: 5.585388835798268, agent episode reward: [5.734092235349681, 5.769716751174532, 5.711701777966449, 5.738735355140295, -11.418277572265156, -5.950579711567532], time: 302.659
steps: 1374975, episodes: 55000, mean episode reward: 2.0969131698313603, agent episode reward: [5.404639519191942, 5.325856340890157, 5.301272981314379, 5.303498737718158, -13.891438580471476, -5.3469158288118], time: 319.561
steps: 1399975, episodes: 56000, mean episode reward: 4.898185324451862, agent episode reward: [6.408057082730903, 6.383839263013355, 6.316196904152566, 6.343484051757659, -14.749474489232053, -5.803917487970568], time: 361.241
steps: 1424975, episodes: 57000, mean episode reward: 3.794920011800356, agent episode reward: [6.156310741941005, 6.065701079154276, 5.999569609974815, 6.079378020671037, -15.330070100088799, -5.175969339851978], time: 336.443
steps: 1449975, episodes: 58000, mean episode reward: 4.876802025939261, agent episode reward: [5.902281365378309, 5.762483537002057, 5.750847051473388, 5.808738044770652, -13.37116400479851, -4.9763839678866315], time: 343.324
steps: 1474975, episodes: 59000, mean episode reward: 2.333858969587541, agent episode reward: [5.502796265031375, 5.400126182127022, 5.372754319790412, 5.3742020635173064, -12.86161800463744, -6.454401856241135], time: 287.619
steps: 1499975, episodes: 60000, mean episode reward: 1.0586424605200015, agent episode reward: [5.313297853315573, 5.263588003764856, 5.290147428692939, 5.2740466194715, -13.400928628228773, -6.681508816496095], time: 266.881
...Finished total of 60001 episodes.
----------------------------------2
----------------------------------3
----------------------------------4
----------------------------------5
----------------------------------6
----------------------------------end
