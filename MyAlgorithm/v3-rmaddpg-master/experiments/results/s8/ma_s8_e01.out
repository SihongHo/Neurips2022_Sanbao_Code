env.action_space is [MultiDiscrete2, Discrete(5), Discrete(5), Discrete(5), Discrete(5), Discrete(5)] 
env.observation_space is [Box(34,), Box(34,), Box(34,), Box(34,), Box(28,), Box(28,)] 
obs_shape_n is [(34,), (34,), (34,), (34,), (28,), (28,)] 
Using good policy maddpg and adv policy maddpg
[Discrete(34), Discrete(34), Discrete(34), Discrete(34), Discrete(28), Discrete(28)]
Using noise policy maddpg
There is 6 adversaries
Starting iterations...
steps: 24975, episodes: 1000, mean episode reward: -51.34108584755546, agent episode reward: [1.3069151498150235, 1.3908883312875082, 1.1211520324289477, 1.371729997987206, -41.050834884869694, -15.480936474204462], time: 156.354
steps: 49975, episodes: 2000, mean episode reward: -22.857646759044048, agent episode reward: [2.1556389931896063, 2.121950634143856, 2.017132763574831, 2.75682784910721, -25.58195486865821, -6.3272421304013395], time: 241.606
steps: 74975, episodes: 3000, mean episode reward: 5.72540081330882, agent episode reward: [3.7760708585349962, 3.5020764101331934, 3.4524135199814583, 3.9580921513706144, -2.6238886321359987, -6.339363494575443], time: 237.777
steps: 99975, episodes: 4000, mean episode reward: 6.969991026842252, agent episode reward: [4.093676633090426, 4.354061444379222, 4.4786826469006575, 4.6095758888275835, -3.502821229824205, -7.06318435653143], time: 250.664
steps: 124975, episodes: 5000, mean episode reward: 6.149801435752829, agent episode reward: [4.166365938022857, 4.033550944779699, 4.1936083145169505, 4.090357026934299, -3.5081211180400715, -6.825959670460906], time: 299.771
steps: 149975, episodes: 6000, mean episode reward: 4.3175709716717074, agent episode reward: [5.085215528602594, 4.9512967449375695, 4.972753964002262, 4.875416617963826, -4.905627877386484, -10.66148400644806], time: 300.008
steps: 174975, episodes: 7000, mean episode reward: 4.556270684252333, agent episode reward: [5.486772551258752, 5.269650564442925, 5.1716152177591574, 5.232591441548412, -5.6262142599274885, -10.978144830829427], time: 301.748
steps: 199975, episodes: 8000, mean episode reward: 8.954301201854513, agent episode reward: [6.432778197765033, 6.267067634223902, 6.28600015646493, 6.259989701642742, -6.014963264272288, -10.276571223969809], time: 299.742
steps: 224975, episodes: 9000, mean episode reward: 6.302379531217146, agent episode reward: [5.605607320791274, 5.568836169592436, 5.477091323194486, 5.619086142025741, -7.2274006634627845, -8.740840760924005], time: 299.432
steps: 249975, episodes: 10000, mean episode reward: 8.952856758941698, agent episode reward: [6.081784456146845, 6.144168668496734, 6.118442575165339, 6.187087805612013, -6.5270593582585805, -9.05156738822065], time: 300.665
steps: 274975, episodes: 11000, mean episode reward: 9.680001144516389, agent episode reward: [6.664223817629316, 6.643134553153702, 6.692780805161421, 6.699539231300541, -7.056631795424063, -9.96304546730453], time: 301.912
steps: 299975, episodes: 12000, mean episode reward: 9.159113967972658, agent episode reward: [6.269313608427263, 6.431461205795332, 6.486516574801945, 6.527908953652576, -6.89735133871441, -9.658735035990045], time: 302.008
steps: 324975, episodes: 13000, mean episode reward: 6.772678617419919, agent episode reward: [5.68882341142933, 5.752731172480693, 5.941997143250968, 5.999449103454701, -6.154000509072954, -10.456321704122816], time: 299.832
steps: 349975, episodes: 14000, mean episode reward: 8.242871066260328, agent episode reward: [6.489121793076319, 6.497417364351563, 6.671969579074371, 6.703233477580279, -8.154414297561493, -9.964456850260714], time: 298.856
steps: 374975, episodes: 15000, mean episode reward: 4.3726419572096855, agent episode reward: [5.764759632836483, 5.793086265881964, 5.9206428352412335, 5.996422986390871, -7.249076044724364, -11.853193718416504], time: 298.562
steps: 399975, episodes: 16000, mean episode reward: 6.309332835635031, agent episode reward: [6.58600118146257, 6.5101545518640895, 6.70304716289804, 6.714196884628699, -8.741942125620975, -11.46212481959739], time: 299.938
steps: 424975, episodes: 17000, mean episode reward: 5.26497144851595, agent episode reward: [6.603061914185453, 6.519510811978578, 6.641386052034119, 6.7099210285912845, -10.270610432816994, -10.938297925456487], time: 299.566
steps: 449975, episodes: 18000, mean episode reward: 5.214982693948111, agent episode reward: [6.408162579991695, 6.389692126737009, 6.486416622669268, 6.568980405478926, -9.112660567165804, -11.525608473762984], time: 300.607
steps: 474975, episodes: 19000, mean episode reward: 2.676184655234546, agent episode reward: [6.606648751615141, 6.6281176207802215, 6.665935797427803, 6.755005049155535, -10.629494795296392, -13.350027768447763], time: 299.986
steps: 499975, episodes: 20000, mean episode reward: 4.69855104316892, agent episode reward: [6.8225281635527475, 6.855767049480336, 6.770405826763592, 6.842636896306838, -8.641842297471012, -13.95094459546358], time: 301.641
steps: 524975, episodes: 21000, mean episode reward: 6.070205290119919, agent episode reward: [6.800127106063041, 6.8250659130948295, 6.811437331010169, 6.863172630802453, -8.253030972522353, -12.976566718328222], time: 301.729
steps: 549975, episodes: 22000, mean episode reward: 7.505446781572082, agent episode reward: [7.206576836776198, 7.1129664916008934, 7.05493343019906, 7.178259898122134, -9.286911801420828, -11.760378073705375], time: 300.214
steps: 574975, episodes: 23000, mean episode reward: 7.521637099584775, agent episode reward: [7.269091919548131, 7.179229229285152, 7.1051136726890185, 7.250949868259748, -10.157368788159042, -11.125378802038231], time: 300.77
steps: 599975, episodes: 24000, mean episode reward: 8.092611969536817, agent episode reward: [7.158232832733612, 7.020244275802404, 7.000924627907198, 7.1362488493567255, -9.679371464421807, -10.543667151841314], time: 252.922
steps: 624975, episodes: 25000, mean episode reward: 4.347446936625378, agent episode reward: [6.972330656124611, 6.890890609705227, 6.824553858260298, 6.914711127312304, -10.349868095443481, -12.905171219333582], time: 237.919
steps: 649975, episodes: 26000, mean episode reward: 7.011867974393757, agent episode reward: [6.977210723910911, 6.903477271866396, 6.8726129300017815, 6.934233868889993, -10.201130769712112, -10.474536050563213], time: 240.503
steps: 674975, episodes: 27000, mean episode reward: 3.996294377315107, agent episode reward: [5.86514196140049, 5.749724403000743, 5.75465169991026, 5.835017435340004, -8.637165480741837, -10.571075641594554], time: 237.274
steps: 699975, episodes: 28000, mean episode reward: 8.269642027818183, agent episode reward: [6.8629997509520155, 6.824023799061956, 6.748808898593497, 6.807949125110158, -9.16201443338332, -9.812125112516119], time: 237.639
steps: 724975, episodes: 29000, mean episode reward: 5.702774881080005, agent episode reward: [6.448354605537319, 6.361503302968925, 6.197586372629554, 6.388894169988764, -9.468587622175026, -10.224975947869533], time: 240.672
steps: 749975, episodes: 30000, mean episode reward: 4.717362934139123, agent episode reward: [6.489682657192066, 6.438232010957068, 6.2976559688131575, 6.4118970451682, -10.806519499262794, -10.113585248728574], time: 237.743
steps: 774975, episodes: 31000, mean episode reward: 5.879621204752509, agent episode reward: [5.990375153521482, 5.923989857924205, 5.805463265784701, 5.891744741031945, -9.104148729028905, -8.627803084480918], time: 241.095
steps: 799975, episodes: 32000, mean episode reward: 9.477722508687174, agent episode reward: [7.248901153642814, 7.228874372604609, 7.084594847794261, 7.1662503339642205, -10.762577501220319, -8.488320698098413], time: 240.529
steps: 824975, episodes: 33000, mean episode reward: 8.263563098825928, agent episode reward: [6.969032834255726, 6.906140312904392, 6.737773839543276, 6.876375147468885, -10.687808855753218, -8.537950179593132], time: 235.734
steps: 849975, episodes: 34000, mean episode reward: 5.639932089010519, agent episode reward: [6.496863031838282, 6.507521525271748, 6.326793692262684, 6.446595842054196, -10.856082569175502, -9.281759433240891], time: 241.102
steps: 874975, episodes: 35000, mean episode reward: 5.587359085195012, agent episode reward: [6.191642457582698, 6.191325165686627, 6.1094108526260476, 6.196808923231243, -10.486337010590335, -8.615491303341267], time: 237.942
steps: 899975, episodes: 36000, mean episode reward: 7.8347208615291, agent episode reward: [6.443218825300171, 6.426630576488187, 6.298836196012169, 6.393722537737756, -10.132880868141376, -7.594806405867806], time: 242.753
steps: 924975, episodes: 37000, mean episode reward: 4.950203181206314, agent episode reward: [6.114514199229377, 6.087196934305297, 6.007251511630702, 6.080430291036088, -11.017831560364346, -8.321358194630804], time: 239.812
steps: 949975, episodes: 38000, mean episode reward: 4.2153995463143765, agent episode reward: [5.946706262774706, 5.895573695915861, 5.839225348326668, 5.879385649879575, -10.660361649031419, -8.685129761551012], time: 236.657
steps: 974975, episodes: 39000, mean episode reward: 5.593555555028813, agent episode reward: [6.723898021013406, 6.6480672268732635, 6.607100416635241, 6.5307544321697355, -11.950723091404317, -8.965541450258511], time: 242.487
steps: 999975, episodes: 40000, mean episode reward: 1.2111853682375744, agent episode reward: [5.651257444948226, 5.552739559814191, 5.532202018587066, 5.368501042430118, -11.79823320359641, -9.095281493945619], time: 242.178
steps: 1024975, episodes: 41000, mean episode reward: -2.3090441540512967, agent episode reward: [5.777941984636324, 5.734655448851103, 5.6808008670760355, 5.605632508089877, -13.280376517290396, -11.82769844541424], time: 239.915
steps: 1049975, episodes: 42000, mean episode reward: 1.7213429120447186, agent episode reward: [6.149753769944837, 6.080329160052338, 5.993665950419283, 5.98367463284372, -11.506774867142465, -10.979305734072994], time: 239.76
steps: 1074975, episodes: 43000, mean episode reward: 6.502553891469145, agent episode reward: [6.96570580816711, 6.921326114838268, 6.808509543357588, 6.765654470274825, -11.600067450309433, -9.358574594859213], time: 242.246
steps: 1099975, episodes: 44000, mean episode reward: 3.882621507356537, agent episode reward: [6.162010589433982, 6.06933159992261, 5.970121835655614, 5.913155649257728, -10.692158990767986, -9.539839176145412], time: 239.696
steps: 1124975, episodes: 45000, mean episode reward: 3.5393154496294628, agent episode reward: [6.757350756193086, 6.6984244690718, 6.6413824392492895, 6.6007372263044655, -12.787890722869822, -10.370688718319357], time: 242.873
steps: 1149975, episodes: 46000, mean episode reward: 2.4230181877247268, agent episode reward: [6.220086582501737, 6.135458713603667, 6.026794335958082, 6.04899903956335, -11.172231062510859, -10.836089421391247], time: 239.218
steps: 1174975, episodes: 47000, mean episode reward: 3.6383339674436703, agent episode reward: [6.608783131026388, 6.522929865493302, 6.43959883963313, 6.456292469515, -10.981976611244237, -11.407293726979912], time: 238.286
steps: 1199975, episodes: 48000, mean episode reward: 3.192665820410769, agent episode reward: [6.415021695173224, 6.232403264455931, 6.216033870572609, 6.196318522598596, -11.137157656707085, -10.729953875682506], time: 236.822
steps: 1224975, episodes: 49000, mean episode reward: 2.9648873438188055, agent episode reward: [6.502314449740235, 6.364105393599701, 6.237323650486338, 6.267219469256552, -11.39523363117527, -11.010841988088748], time: 239.732
steps: 1249975, episodes: 50000, mean episode reward: 0.7072886770013944, agent episode reward: [6.338132977257677, 6.2770747326203775, 6.189876237017228, 6.129518622803185, -11.83159870911923, -12.395715183577842], time: 242.884
steps: 1274975, episodes: 51000, mean episode reward: 0.238016889803524, agent episode reward: [6.143352170702783, 6.045144836063377, 5.985003821483625, 5.959296339071555, -11.706226485278453, -12.18855379223936], time: 241.605
steps: 1299975, episodes: 52000, mean episode reward: 2.2457014935764836, agent episode reward: [6.559202690347274, 6.4430512177871515, 6.382394071433552, 6.342057513135106, -12.205082185411806, -11.275921813714795], time: 238.948
steps: 1324975, episodes: 53000, mean episode reward: 2.5642313697013908, agent episode reward: [6.536412881868157, 6.422841174743611, 6.313801063568721, 6.257524538395492, -11.87981362453223, -11.086534664342356], time: 242.66
steps: 1349975, episodes: 54000, mean episode reward: 3.72484666084537, agent episode reward: [6.3732302472145275, 6.254448980277686, 6.142368704307294, 6.020170849712468, -9.540060039320155, -11.52531208134645], time: 241.026
steps: 1374975, episodes: 55000, mean episode reward: 5.51981336242663, agent episode reward: [6.8021747765434375, 6.722657998229702, 6.5232683492949315, 6.404458799074222, -10.916015188713532, -10.01673137200213], time: 240.965
steps: 1399975, episodes: 56000, mean episode reward: 6.293574368393226, agent episode reward: [7.02010735789426, 6.958560522368554, 6.779356985859993, 6.698327540198788, -10.865758132596957, -10.297019905331412], time: 242.125
steps: 1424975, episodes: 57000, mean episode reward: 3.4256964006659865, agent episode reward: [6.533440382931756, 6.460524865322107, 6.361608823468978, 6.293525183631767, -11.460933731237647, -10.762469123450975], time: 240.736
steps: 1449975, episodes: 58000, mean episode reward: 6.903741444014978, agent episode reward: [6.9862523153882705, 6.9552926307126235, 6.7912694934255295, 6.774566152296354, -10.597078832267842, -10.006560315539957], time: 240.636
steps: 1474975, episodes: 59000, mean episode reward: 4.432474868470242, agent episode reward: [6.527728252043614, 6.420820949524131, 6.265699090480122, 6.2319135780210075, -11.974948230015773, -9.038738771582857], time: 243.268
steps: 1499975, episodes: 60000, mean episode reward: 3.788052956761099, agent episode reward: [6.631525111831375, 6.568816890713689, 6.430828721734968, 6.300962365334046, -11.112226973389655, -11.031853159463324], time: 243.328
...Finished total of 60001 episodes.
