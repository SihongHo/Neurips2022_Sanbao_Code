env.action_space is [MultiDiscrete2, MultiDiscrete2] 
env.observation_space is [Box(21,), Box(21,)] 
obs_shape_n is [(21,), (21,)] 
Using good policy maddpg and adv policy maddpg
[Discrete(21), Discrete(21)]
Using noise policy maddpg
There is 2 adversaries
Loading previous state...
Starting iterations...
Finished agent benchmarking, now saving...
